<!doctype html><html lang=en dir=auto data-theme=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全） | Blog</title><meta name=keywords content><meta name=description content="WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全）
起因：听着音声，突然想起自己半途而废的日语学习，遂有此。

目标：输入一个 YouTube URL，自动下载视频/音频，用 Whisper 转录成日语台本（txt）与字幕（srt/vtt），并把所有产物放进以“视频标题”命名的文件夹中。
环境：WSL2（Ubuntu）+ conda + NVIDIA GPU（以 RTX 4060 8GB 为例）


1. 总览：流水线与目录结构
流水线：

YouTube URL
yt-dlp 下载视频（或仅音频）
ffmpeg 抽取 / 规整音频（16kHz、单声道 wav）
whisper（openai-whisper CLI）转录
输出：txt（台本）、srt/vtt（字幕）、json（结构化段落信息）

推荐目录结构（按视频标题建文件夹）：
<视频标题>/
  meta.json               # 可选：yt-dlp 元信息（含标题、时长、频道等）
  video.mp4               # 下载视频
  audio_16k_mono.wav      # Whisper 最稳输入
  audio_16k_mono.txt      # 台本
  audio_16k_mono.srt      # 字幕（时间轴）
  audio_16k_mono.vtt
  audio_16k_mono.json

2. 环境选择：为什么推荐 Python 3.10（conda）
结论：Python 3.10 是 Whisper 工具链最省心的版本。
理由（工程视角）：

openai-whisper、yt-dlp、ffmpeg 组合在 3.10 上兼容性最好
GPU 相关的 torch wheel / conda 包覆盖最稳
3.11/3.12 更容易遇到二进制依赖的“版本锁”或源码编译回退

创建环境："><meta name=author content><link rel=canonical href=https://analyst-huang.github.io/posts/%E6%9D%82%E8%B0%88/wsl_conda_gpu_whisper_youtube_ja_tech_blog/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://analyst-huang.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://analyst-huang.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://analyst-huang.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://analyst-huang.github.io/apple-touch-icon.png><link rel=mask-icon href=https://analyst-huang.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://analyst-huang.github.io/posts/%E6%9D%82%E8%B0%88/wsl_conda_gpu_whisper_youtube_ja_tech_blog/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><meta property="og:url" content="https://analyst-huang.github.io/posts/%E6%9D%82%E8%B0%88/wsl_conda_gpu_whisper_youtube_ja_tech_blog/"><meta property="og:site_name" content="Blog"><meta property="og:title" content="WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全）"><meta property="og:description" content="WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全） 起因：听着音声，突然想起自己半途而废的日语学习，遂有此。
目标：输入一个 YouTube URL，自动下载视频/音频，用 Whisper 转录成日语台本（txt）与字幕（srt/vtt），并把所有产物放进以“视频标题”命名的文件夹中。
环境：WSL2（Ubuntu）+ conda + NVIDIA GPU（以 RTX 4060 8GB 为例）
1. 总览：流水线与目录结构 流水线：
YouTube URL yt-dlp 下载视频（或仅音频） ffmpeg 抽取 / 规整音频（16kHz、单声道 wav） whisper（openai-whisper CLI）转录 输出：txt（台本）、srt/vtt（字幕）、json（结构化段落信息） 推荐目录结构（按视频标题建文件夹）：
<视频标题>/ meta.json # 可选：yt-dlp 元信息（含标题、时长、频道等） video.mp4 # 下载视频 audio_16k_mono.wav # Whisper 最稳输入 audio_16k_mono.txt # 台本 audio_16k_mono.srt # 字幕（时间轴） audio_16k_mono.vtt audio_16k_mono.json 2. 环境选择：为什么推荐 Python 3.10（conda） 结论：Python 3.10 是 Whisper 工具链最省心的版本。
理由（工程视角）：
openai-whisper、yt-dlp、ffmpeg 组合在 3.10 上兼容性最好 GPU 相关的 torch wheel / conda 包覆盖最稳 3.11/3.12 更容易遇到二进制依赖的“版本锁”或源码编译回退 创建环境："><meta property="og:locale" content="zh-cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-02-05T00:00:00+00:00"><meta property="article:modified_time" content="2026-02-05T00:00:00+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全）"><meta name=twitter:description content="WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全）
起因：听着音声，突然想起自己半途而废的日语学习，遂有此。

目标：输入一个 YouTube URL，自动下载视频/音频，用 Whisper 转录成日语台本（txt）与字幕（srt/vtt），并把所有产物放进以“视频标题”命名的文件夹中。
环境：WSL2（Ubuntu）+ conda + NVIDIA GPU（以 RTX 4060 8GB 为例）


1. 总览：流水线与目录结构
流水线：

YouTube URL
yt-dlp 下载视频（或仅音频）
ffmpeg 抽取 / 规整音频（16kHz、单声道 wav）
whisper（openai-whisper CLI）转录
输出：txt（台本）、srt/vtt（字幕）、json（结构化段落信息）

推荐目录结构（按视频标题建文件夹）：
<视频标题>/
  meta.json               # 可选：yt-dlp 元信息（含标题、时长、频道等）
  video.mp4               # 下载视频
  audio_16k_mono.wav      # Whisper 最稳输入
  audio_16k_mono.txt      # 台本
  audio_16k_mono.srt      # 字幕（时间轴）
  audio_16k_mono.vtt
  audio_16k_mono.json

2. 环境选择：为什么推荐 Python 3.10（conda）
结论：Python 3.10 是 Whisper 工具链最省心的版本。
理由（工程视角）：

openai-whisper、yt-dlp、ffmpeg 组合在 3.10 上兼容性最好
GPU 相关的 torch wheel / conda 包覆盖最稳
3.11/3.12 更容易遇到二进制依赖的“版本锁”或源码编译回退

创建环境："><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://analyst-huang.github.io/posts/"},{"@type":"ListItem","position":3,"name":"WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全）","item":"https://analyst-huang.github.io/posts/%E6%9D%82%E8%B0%88/wsl_conda_gpu_whisper_youtube_ja_tech_blog/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全）","name":"WSL \u002b Conda \u002b GPU Whisper：从 YouTube 日语音声到台本\/字幕的一站式流水线（含踩坑大全）","description":"WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全） 起因：听着音声，突然想起自己半途而废的日语学习，遂有此。\n目标：输入一个 YouTube URL，自动下载视频/音频，用 Whisper 转录成日语台本（txt）与字幕（srt/vtt），并把所有产物放进以“视频标题”命名的文件夹中。\n环境：WSL2（Ubuntu）+ conda + NVIDIA GPU（以 RTX 4060 8GB 为例）\n1. 总览：流水线与目录结构 流水线：\nYouTube URL yt-dlp 下载视频（或仅音频） ffmpeg 抽取 / 规整音频（16kHz、单声道 wav） whisper（openai-whisper CLI）转录 输出：txt（台本）、srt/vtt（字幕）、json（结构化段落信息） 推荐目录结构（按视频标题建文件夹）：\n\u0026lt;视频标题\u0026gt;/ meta.json # 可选：yt-dlp 元信息（含标题、时长、频道等） video.mp4 # 下载视频 audio_16k_mono.wav # Whisper 最稳输入 audio_16k_mono.txt # 台本 audio_16k_mono.srt # 字幕（时间轴） audio_16k_mono.vtt audio_16k_mono.json 2. 环境选择：为什么推荐 Python 3.10（conda） 结论：Python 3.10 是 Whisper 工具链最省心的版本。\n理由（工程视角）：\nopenai-whisper、yt-dlp、ffmpeg 组合在 3.10 上兼容性最好 GPU 相关的 torch wheel / conda 包覆盖最稳 3.11/3.12 更容易遇到二进制依赖的“版本锁”或源码编译回退 创建环境：\n","keywords":[],"articleBody":"WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全） 起因：听着音声，突然想起自己半途而废的日语学习，遂有此。\n目标：输入一个 YouTube URL，自动下载视频/音频，用 Whisper 转录成日语台本（txt）与字幕（srt/vtt），并把所有产物放进以“视频标题”命名的文件夹中。\n环境：WSL2（Ubuntu）+ conda + NVIDIA GPU（以 RTX 4060 8GB 为例）\n1. 总览：流水线与目录结构 流水线：\nYouTube URL yt-dlp 下载视频（或仅音频） ffmpeg 抽取 / 规整音频（16kHz、单声道 wav） whisper（openai-whisper CLI）转录 输出：txt（台本）、srt/vtt（字幕）、json（结构化段落信息） 推荐目录结构（按视频标题建文件夹）：\n\u003c视频标题\u003e/ meta.json # 可选：yt-dlp 元信息（含标题、时长、频道等） video.mp4 # 下载视频 audio_16k_mono.wav # Whisper 最稳输入 audio_16k_mono.txt # 台本 audio_16k_mono.srt # 字幕（时间轴） audio_16k_mono.vtt audio_16k_mono.json 2. 环境选择：为什么推荐 Python 3.10（conda） 结论：Python 3.10 是 Whisper 工具链最省心的版本。\n理由（工程视角）：\nopenai-whisper、yt-dlp、ffmpeg 组合在 3.10 上兼容性最好 GPU 相关的 torch wheel / conda 包覆盖最稳 3.11/3.12 更容易遇到二进制依赖的“版本锁”或源码编译回退 创建环境：\nconda create -n whisper python=3.10 -y conda activate whisper python -m pip install -U pip 3. GPU 基础检查：确认 WSL 真的能用 GPU 3.1 WSL 内确认 GPU 直通 nvidia-smi 能看到 GPU 型号/驱动版本即为 OK。\n3.2 Python 侧确认 CUDA 可用（torch） python -c \"import torch; print(torch.__version__); print('cuda:', torch.cuda.is_available()); print('device:', torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)\" 4. PyTorch 关键坑 ①：ImportError iJIT_NotifyEvent（MKL/Intel OpenMP 版本冲突） 4.1 症状 运行 import torch 报：\nImportError: ... libtorch_cpu.so: undefined symbol: iJIT_NotifyEvent 4.2 根因（常见） conda 环境中 MKL / intel-openmp 过新（例如 2025.x），导致 libtorch_cpu.so 动态链接时符号不匹配。\n4.3 修复策略（推荐） 把 MKL / intel-openmp pin 到兼容版本（例如 2024.0 系列），并补齐 ITT 运行库：\nconda install -y \"mkl=2024.*\" 工程建议：“不要追新 MKL”，优先追能稳定提供 wheel 的组合。音声学习这种高频工具链，稳定性价值远大于“最新”。\n5. PyTorch 关键坑 ②：torch.cuda.is_available()==False（即使 nvidia-smi 正常） 解决办法 不太推荐用conda安装torch等，用pip显示指定GPU版本会好很多\n6. ffmpeg 关键坑：apt 找不到 ffmpeg（Ubuntu 未启用 universe） 6.1 症状 E: Unable to locate package ffmpeg 或提示 snap。\n6.2 根因 WSL/Ubuntu 精简安装常常未启用 universe 软件源，而 ffmpeg 位于 universe。\n6.3 修复（推荐用 apt，不推荐 snap） sudo add-apt-repository universe sudo apt update sudo apt install -y ffmpeg ffmpeg -version 7. 代理关键坑：Windows “全局代理”不等于 WSL 终端走代理 7.1 症状 浏览器能访问 YouTube WSL 中 yt-dlp 仍然无法下载 7.2 根因 WSL 中的 Linux 进程不会自动继承 Windows 代理设置。yt-dlp 只会用：\n--proxy 参数 或环境变量 http_proxy / https_proxy / all_proxy 或 cookies / 登录等机制 7.3 最常见误区：用 /etc/resolv.conf 的 nameserver 当“Windows 主机 IP” /etc/resolv.conf 的 nameserver 是 DNS 转发器地址，不等于 Windows 主机网关地址，拿它当代理地址常导致：\nConnection refused 7.4 正确做法：从路由表拿 Windows 网关 IP WIN_IP=$(ip route | awk '/default/ {print $3}') echo $WIN_IP 7.5 端口探测（非常有效） 假设你的代理 HTTP 端口是 7890，SOCKS5 是 7891：\nsudo apt install -y netcat-openbsd nc -vz $WIN_IP 7890 nc -vz $WIN_IP 7891 succeeded/open：端口可达 refused：代理没开“允许局域网连接/Allow LAN”或只绑定在 127.0.0.1 7.6 让 yt-dlp 走代理 yt-dlp --proxy \"http://$WIN_IP:7890\" \"\" # 或 yt-dlp --proxy \"socks5://$WIN_IP:7891\" \"\" 7.7 永久设置（可选） export http_proxy=\"http://$WIN_IP:7890\" export https_proxy=\"http://$WIN_IP:7890\" export all_proxy=\"socks5://$WIN_IP:7891\" 8. yt-dlp 下载策略：视频/音频、合并格式与常用命令 8.1 下载最兼容的 mp4（视频+音频合并） yt-dlp -f \"bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4]\" --merge-output-format mp4 \"\" 参数解读：\nbv*：最佳视频流（prefer mp4） ba：最佳音频流（prefer m4a） +：合并 /：回退策略（找不到就选单文件 mp4） 8.2 只下载音频（为转录而生） yt-dlp -f ba -x --audio-format m4a \"\" 8.3 受限视频（登录/年龄限制）常用手段 从浏览器导入 cookies：\nyt-dlp --cookies-from-browser chrome \"\" 9. 音频预处理：统一成 16k 单声道 wav（Whisper 最稳输入） 即便 Whisper 能直接吃 mp4/m4a，也建议统一预处理，提高稳定性并减少玄学问题：\nffmpeg -i \"video.mp4\" -ac 1 -ar 16000 -vn \"audio_16k_mono.wav\" 10. Whisper 使用方法：模型选择、输出格式与 GPU/CPU 10.1 安装（CLI） pip install -U openai-whisper 10.2 核心命令（建议输出 all：txt+srt+vtt+json） whisper \"audio_16k_mono.wav\" --language ja --task transcribe --model medium --device cuda --output_format all --output_dir out 10.3 模型选择建议（以 8GB 显存为例） 日常稳态：medium 快速预览：small large 不推荐（显存压力、速度压力明显） 实测经验：medium 在 RTX 4060 8GB 上显存占用约 ~5GB 属于正常范围，说明 FP16 推理链路通常是对的。\n10.4 GPU 不可用时先用 CPU 跑通流程（务实策略） whisper \"audio_16k_mono.wav\" --language ja --task transcribe --model small --device cpu --output_format srt --output_dir out 11. 一键自动化：Python 脚本实现（URL -\u003e 文件夹 -\u003e 全部产物） 推荐把流程固化成脚本，输入 URL 自动：\n用 yt-dlp -J 取视频标题 创建以标题命名的文件夹 下载 video.mp4 ffmpeg 抽 audio_16k_mono.wav whisper 输出台本/字幕到同一目录 实践建议：脚本中把代理作为参数 --proxy，并对标题做文件名清洗（Windows/Unix 都安全）。\n12. 排障速查清单（按概率从高到低） 下载失败（yt-dlp） pip install -U yt-dlp（优先） 代理未传入 WSL（见第 7 节） 需要 cookies（见 8.3） ffmpeg 不存在 启用 universe 并安装（见第 6 节） torch import 报 iJIT_NotifyEvent 降级 MKL/Intel OpenMP（见第 4 节） nvidia-smi 正常但 torch.cuda False 添加 /usr/lib/wsl/lib 到 ldconfig（见第 5 节） 排查 LD_LIBRARY_PATH 劫持（见第 5.4 节） 参考链接 https://github.com/yt-dlp/yt-dlp https://github.com/openai/whisper https://pytorch.org/get-started/locally/ https://ffmpeg.org/ ","wordCount":"541","inLanguage":"en","datePublished":"2026-02-05T00:00:00Z","dateModified":"2026-02-05T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://analyst-huang.github.io/posts/%E6%9D%82%E8%B0%88/wsl_conda_gpu_whisper_youtube_ja_tech_blog/"},"publisher":{"@type":"Organization","name":"Blog","logo":{"@type":"ImageObject","url":"https://analyst-huang.github.io/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://analyst-huang.github.io/ accesskey=h title="Blog (Alt + H)">Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://analyst-huang.github.io/posts/ title=文章><span>文章</span></a></li><li><a href=https://analyst-huang.github.io/about/ title=关于><span>关于</span></a></li><li><a href=https://analyst-huang.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://analyst-huang.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://analyst-huang.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全）</h1><div class=post-meta><span title='2026-02-05 00:00:00 +0000 UTC'>February 5, 2026</span>&nbsp;·&nbsp;<span>3 min</span></div></header><div class=post-content><h1 id=wsl--conda--gpu-whisper从-youtube-日语音声到台本字幕的一站式流水线含踩坑大全>WSL + Conda + GPU Whisper：从 YouTube 日语音声到台本/字幕的一站式流水线（含踩坑大全）<a hidden class=anchor aria-hidden=true href=#wsl--conda--gpu-whisper从-youtube-日语音声到台本字幕的一站式流水线含踩坑大全>#</a></h1><p>起因：听着音声，突然想起自己半途而废的日语学习，遂有此。</p><blockquote><p>目标：输入一个 YouTube URL，自动下载视频/音频，用 Whisper 转录成日语台本（txt）与字幕（srt/vtt），并把所有产物放进以“视频标题”命名的文件夹中。<br>环境：WSL2（Ubuntu）+ conda + NVIDIA GPU（以 RTX 4060 8GB 为例）</p></blockquote><hr><h2 id=1-总览流水线与目录结构>1. 总览：流水线与目录结构<a hidden class=anchor aria-hidden=true href=#1-总览流水线与目录结构>#</a></h2><p><strong>流水线：</strong></p><ol><li>YouTube URL</li><li><code>yt-dlp</code> 下载视频（或仅音频）</li><li><code>ffmpeg</code> 抽取 / 规整音频（16kHz、单声道 wav）</li><li><code>whisper</code>（openai-whisper CLI）转录</li><li>输出：<code>txt</code>（台本）、<code>srt/vtt</code>（字幕）、<code>json</code>（结构化段落信息）</li></ol><p><strong>推荐目录结构（按视频标题建文件夹）：</strong></p><pre tabindex=0><code>&lt;视频标题&gt;/
  meta.json               # 可选：yt-dlp 元信息（含标题、时长、频道等）
  video.mp4               # 下载视频
  audio_16k_mono.wav      # Whisper 最稳输入
  audio_16k_mono.txt      # 台本
  audio_16k_mono.srt      # 字幕（时间轴）
  audio_16k_mono.vtt
  audio_16k_mono.json
</code></pre><hr><h2 id=2-环境选择为什么推荐-python-310conda>2. 环境选择：为什么推荐 Python 3.10（conda）<a hidden class=anchor aria-hidden=true href=#2-环境选择为什么推荐-python-310conda>#</a></h2><p><strong>结论：Python 3.10 是 Whisper 工具链最省心的版本。</strong></p><p>理由（工程视角）：</p><ul><li><code>openai-whisper</code>、<code>yt-dlp</code>、<code>ffmpeg</code> 组合在 3.10 上兼容性最好</li><li>GPU 相关的 <code>torch</code> wheel / conda 包覆盖最稳</li><li>3.11/3.12 更容易遇到二进制依赖的“版本锁”或源码编译回退</li></ul><p><strong>创建环境：</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>conda create -n whisper python<span style=color:#f92672>=</span>3.10 -y
</span></span><span style=display:flex><span>conda activate whisper
</span></span><span style=display:flex><span>python -m pip install -U pip
</span></span></code></pre></div><hr><h2 id=3-gpu-基础检查确认-wsl-真的能用-gpu>3. GPU 基础检查：确认 WSL 真的能用 GPU<a hidden class=anchor aria-hidden=true href=#3-gpu-基础检查确认-wsl-真的能用-gpu>#</a></h2><h3 id=31-wsl-内确认-gpu-直通>3.1 WSL 内确认 GPU 直通<a hidden class=anchor aria-hidden=true href=#31-wsl-内确认-gpu-直通>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>nvidia-smi
</span></span></code></pre></div><p>能看到 GPU 型号/驱动版本即为 OK。</p><h3 id=32-python-侧确认-cuda-可用torch>3.2 Python 侧确认 CUDA 可用（torch）<a hidden class=anchor aria-hidden=true href=#32-python-侧确认-cuda-可用torch>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>python -c <span style=color:#e6db74>&#34;import torch; print(torch.__version__); print(&#39;cuda:&#39;, torch.cuda.is_available()); print(&#39;device:&#39;, torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)&#34;</span>
</span></span></code></pre></div><hr><h2 id=4-pytorch-关键坑-importerror-ijit_notifyeventmklintel-openmp-版本冲突>4. PyTorch 关键坑 ①：ImportError <code>iJIT_NotifyEvent</code>（MKL/Intel OpenMP 版本冲突）<a hidden class=anchor aria-hidden=true href=#4-pytorch-关键坑-importerror-ijit_notifyeventmklintel-openmp-版本冲突>#</a></h2><h3 id=41-症状>4.1 症状<a hidden class=anchor aria-hidden=true href=#41-症状>#</a></h3><p>运行 <code>import torch</code> 报：</p><pre tabindex=0><code>ImportError: ... libtorch_cpu.so: undefined symbol: iJIT_NotifyEvent
</code></pre><h3 id=42-根因常见>4.2 根因（常见）<a hidden class=anchor aria-hidden=true href=#42-根因常见>#</a></h3><p>conda 环境中 <strong>MKL / intel-openmp 过新（例如 2025.x）</strong>，导致 <code>libtorch_cpu.so</code> 动态链接时符号不匹配。</p><h3 id=43-修复策略推荐>4.3 修复策略（推荐）<a hidden class=anchor aria-hidden=true href=#43-修复策略推荐>#</a></h3><p>把 MKL / intel-openmp pin 到兼容版本（例如 2024.0 系列），并补齐 ITT 运行库：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>conda install -y <span style=color:#e6db74>&#34;mkl=2024.*&#34;</span>
</span></span></code></pre></div><blockquote><p>工程建议：<strong>“不要追新 MKL”，优先追能稳定提供 wheel 的组合</strong>。音声学习这种高频工具链，稳定性价值远大于“最新”。</p></blockquote><hr><h2 id=5-pytorch-关键坑-torchcudais_availablefalse即使-nvidia-smi-正常>5. PyTorch 关键坑 ②：<code>torch.cuda.is_available()==False</code>（即使 nvidia-smi 正常）<a hidden class=anchor aria-hidden=true href=#5-pytorch-关键坑-torchcudais_availablefalse即使-nvidia-smi-正常>#</a></h2><h3 id=解决办法>解决办法<a hidden class=anchor aria-hidden=true href=#解决办法>#</a></h3><p>不太推荐用conda安装torch等，用pip显示指定GPU版本会好很多</p><hr><h2 id=6-ffmpeg-关键坑apt-找不到-ffmpegubuntu-未启用-universe>6. ffmpeg 关键坑：apt 找不到 <code>ffmpeg</code>（Ubuntu 未启用 universe）<a hidden class=anchor aria-hidden=true href=#6-ffmpeg-关键坑apt-找不到-ffmpegubuntu-未启用-universe>#</a></h2><h3 id=61-症状>6.1 症状<a hidden class=anchor aria-hidden=true href=#61-症状>#</a></h3><pre tabindex=0><code>E: Unable to locate package ffmpeg
</code></pre><p>或提示 snap。</p><h3 id=62-根因>6.2 根因<a hidden class=anchor aria-hidden=true href=#62-根因>#</a></h3><p>WSL/Ubuntu 精简安装常常未启用 <code>universe</code> 软件源，而 <code>ffmpeg</code> 位于 <code>universe</code>。</p><h3 id=63-修复推荐用-apt不推荐-snap>6.3 修复（推荐用 apt，不推荐 snap）<a hidden class=anchor aria-hidden=true href=#63-修复推荐用-apt不推荐-snap>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>sudo add-apt-repository universe
</span></span><span style=display:flex><span>sudo apt update
</span></span><span style=display:flex><span>sudo apt install -y ffmpeg
</span></span><span style=display:flex><span>ffmpeg -version
</span></span></code></pre></div><hr><h2 id=7-代理关键坑windows-全局代理不等于-wsl-终端走代理>7. 代理关键坑：Windows “全局代理”不等于 WSL 终端走代理<a hidden class=anchor aria-hidden=true href=#7-代理关键坑windows-全局代理不等于-wsl-终端走代理>#</a></h2><h3 id=71-症状>7.1 症状<a hidden class=anchor aria-hidden=true href=#71-症状>#</a></h3><ul><li>浏览器能访问 YouTube</li><li>WSL 中 <code>yt-dlp</code> 仍然无法下载</li></ul><h3 id=72-根因>7.2 根因<a hidden class=anchor aria-hidden=true href=#72-根因>#</a></h3><p>WSL 中的 Linux 进程不会自动继承 Windows 代理设置。<code>yt-dlp</code> 只会用：</p><ul><li><code>--proxy</code> 参数</li><li>或环境变量 <code>http_proxy / https_proxy / all_proxy</code></li><li>或 cookies / 登录等机制</li></ul><h3 id=73-最常见误区用-etcresolvconf-的-nameserver-当windows-主机-ip>7.3 最常见误区：用 <code>/etc/resolv.conf</code> 的 <code>nameserver</code> 当“Windows 主机 IP”<a hidden class=anchor aria-hidden=true href=#73-最常见误区用-etcresolvconf-的-nameserver-当windows-主机-ip>#</a></h3><p><code>/etc/resolv.conf</code> 的 <code>nameserver</code> 是 <strong>DNS 转发器地址</strong>，不等于 Windows 主机网关地址，拿它当代理地址常导致：</p><pre tabindex=0><code>Connection refused
</code></pre><h3 id=74-正确做法从路由表拿-windows-网关-ip>7.4 正确做法：从路由表拿 Windows 网关 IP<a hidden class=anchor aria-hidden=true href=#74-正确做法从路由表拿-windows-网关-ip>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>WIN_IP<span style=color:#f92672>=</span><span style=color:#66d9ef>$(</span>ip route | awk <span style=color:#e6db74>&#39;/default/ {print $3}&#39;</span><span style=color:#66d9ef>)</span>
</span></span><span style=display:flex><span>echo $WIN_IP
</span></span></code></pre></div><h3 id=75-端口探测非常有效>7.5 端口探测（非常有效）<a hidden class=anchor aria-hidden=true href=#75-端口探测非常有效>#</a></h3><p>假设你的代理 HTTP 端口是 7890，SOCKS5 是 7891：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>sudo apt install -y netcat-openbsd
</span></span><span style=display:flex><span>nc -vz $WIN_IP <span style=color:#ae81ff>7890</span>
</span></span><span style=display:flex><span>nc -vz $WIN_IP <span style=color:#ae81ff>7891</span>
</span></span></code></pre></div><ul><li>succeeded/open：端口可达</li><li>refused：代理没开“允许局域网连接/Allow LAN”或只绑定在 127.0.0.1</li></ul><h3 id=76-让-yt-dlp-走代理>7.6 让 yt-dlp 走代理<a hidden class=anchor aria-hidden=true href=#76-让-yt-dlp-走代理>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>yt-dlp --proxy <span style=color:#e6db74>&#34;http://</span>$WIN_IP<span style=color:#e6db74>:7890&#34;</span> <span style=color:#e6db74>&#34;&lt;URL&gt;&#34;</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 或</span>
</span></span><span style=display:flex><span>yt-dlp --proxy <span style=color:#e6db74>&#34;socks5://</span>$WIN_IP<span style=color:#e6db74>:7891&#34;</span> <span style=color:#e6db74>&#34;&lt;URL&gt;&#34;</span>
</span></span></code></pre></div><h3 id=77-永久设置可选>7.7 永久设置（可选）<a hidden class=anchor aria-hidden=true href=#77-永久设置可选>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>export http_proxy<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;http://</span>$WIN_IP<span style=color:#e6db74>:7890&#34;</span>
</span></span><span style=display:flex><span>export https_proxy<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;http://</span>$WIN_IP<span style=color:#e6db74>:7890&#34;</span>
</span></span><span style=display:flex><span>export all_proxy<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;socks5://</span>$WIN_IP<span style=color:#e6db74>:7891&#34;</span>
</span></span></code></pre></div><hr><h2 id=8-yt-dlp-下载策略视频音频合并格式与常用命令>8. yt-dlp 下载策略：视频/音频、合并格式与常用命令<a hidden class=anchor aria-hidden=true href=#8-yt-dlp-下载策略视频音频合并格式与常用命令>#</a></h2><h3 id=81-下载最兼容的-mp4视频音频合并>8.1 下载最兼容的 mp4（视频+音频合并）<a hidden class=anchor aria-hidden=true href=#81-下载最兼容的-mp4视频音频合并>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>yt-dlp   -f <span style=color:#e6db74>&#34;bv*[ext=mp4]+ba[ext=m4a]/b[ext=mp4]&#34;</span>   --merge-output-format mp4   <span style=color:#e6db74>&#34;&lt;YouTube_URL&gt;&#34;</span>
</span></span></code></pre></div><p>参数解读：</p><ul><li><code>bv*</code>：最佳视频流（prefer mp4）</li><li><code>ba</code>：最佳音频流（prefer m4a）</li><li><code>+</code>：合并</li><li><code>/</code>：回退策略（找不到就选单文件 mp4）</li></ul><h3 id=82-只下载音频为转录而生>8.2 只下载音频（为转录而生）<a hidden class=anchor aria-hidden=true href=#82-只下载音频为转录而生>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>yt-dlp -f ba -x --audio-format m4a <span style=color:#e6db74>&#34;&lt;YouTube_URL&gt;&#34;</span>
</span></span></code></pre></div><h3 id=83-受限视频登录年龄限制常用手段>8.3 受限视频（登录/年龄限制）常用手段<a hidden class=anchor aria-hidden=true href=#83-受限视频登录年龄限制常用手段>#</a></h3><p>从浏览器导入 cookies：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>yt-dlp --cookies-from-browser chrome <span style=color:#e6db74>&#34;&lt;YouTube_URL&gt;&#34;</span>
</span></span></code></pre></div><hr><h2 id=9-音频预处理统一成-16k-单声道-wavwhisper-最稳输入>9. 音频预处理：统一成 16k 单声道 wav（Whisper 最稳输入）<a hidden class=anchor aria-hidden=true href=#9-音频预处理统一成-16k-单声道-wavwhisper-最稳输入>#</a></h2><p>即便 Whisper 能直接吃 mp4/m4a，也建议统一预处理，提高稳定性并减少玄学问题：</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>ffmpeg -i <span style=color:#e6db74>&#34;video.mp4&#34;</span> -ac <span style=color:#ae81ff>1</span> -ar <span style=color:#ae81ff>16000</span> -vn <span style=color:#e6db74>&#34;audio_16k_mono.wav&#34;</span>
</span></span></code></pre></div><hr><h2 id=10-whisper-使用方法模型选择输出格式与-gpucpu>10. Whisper 使用方法：模型选择、输出格式与 GPU/CPU<a hidden class=anchor aria-hidden=true href=#10-whisper-使用方法模型选择输出格式与-gpucpu>#</a></h2><h3 id=101-安装cli>10.1 安装（CLI）<a hidden class=anchor aria-hidden=true href=#101-安装cli>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>pip install -U openai-whisper
</span></span></code></pre></div><h3 id=102-核心命令建议输出-alltxtsrtvttjson>10.2 核心命令（建议输出 all：txt+srt+vtt+json）<a hidden class=anchor aria-hidden=true href=#102-核心命令建议输出-alltxtsrtvttjson>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>whisper <span style=color:#e6db74>&#34;audio_16k_mono.wav&#34;</span>   --language ja   --task transcribe   --model medium   --device cuda   --output_format all   --output_dir out
</span></span></code></pre></div><h3 id=103-模型选择建议以-8gb-显存为例>10.3 模型选择建议（以 8GB 显存为例）<a hidden class=anchor aria-hidden=true href=#103-模型选择建议以-8gb-显存为例>#</a></h3><ul><li>日常稳态：<code>medium</code></li><li>快速预览：<code>small</code></li><li><code>large</code> 不推荐（显存压力、速度压力明显）</li></ul><blockquote><p>实测经验：<code>medium</code> 在 RTX 4060 8GB 上显存占用约 ~5GB 属于正常范围，说明 FP16 推理链路通常是对的。</p></blockquote><h3 id=104-gpu-不可用时先用-cpu-跑通流程务实策略>10.4 GPU 不可用时先用 CPU 跑通流程（务实策略）<a hidden class=anchor aria-hidden=true href=#104-gpu-不可用时先用-cpu-跑通流程务实策略>#</a></h3><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-bash data-lang=bash><span style=display:flex><span>whisper <span style=color:#e6db74>&#34;audio_16k_mono.wav&#34;</span> --language ja --task transcribe --model small --device cpu --output_format srt --output_dir out
</span></span></code></pre></div><hr><h2 id=11-一键自动化python-脚本实现url---文件夹---全部产物>11. 一键自动化：Python 脚本实现（URL -> 文件夹 -> 全部产物）<a hidden class=anchor aria-hidden=true href=#11-一键自动化python-脚本实现url---文件夹---全部产物>#</a></h2><p>推荐把流程固化成脚本，输入 URL 自动：</p><ul><li>用 <code>yt-dlp -J</code> 取视频标题</li><li>创建以标题命名的文件夹</li><li>下载 <code>video.mp4</code></li><li><code>ffmpeg</code> 抽 <code>audio_16k_mono.wav</code></li><li><code>whisper</code> 输出台本/字幕到同一目录</li></ul><blockquote><p>实践建议：脚本中把代理作为参数 <code>--proxy</code>，并对标题做文件名清洗（Windows/Unix 都安全）。</p></blockquote><hr><h2 id=12-排障速查清单按概率从高到低>12. 排障速查清单（按概率从高到低）<a hidden class=anchor aria-hidden=true href=#12-排障速查清单按概率从高到低>#</a></h2><h3 id=下载失败yt-dlp>下载失败（yt-dlp）<a hidden class=anchor aria-hidden=true href=#下载失败yt-dlp>#</a></h3><ul><li><code>pip install -U yt-dlp</code>（优先）</li><li>代理未传入 WSL（见第 7 节）</li><li>需要 cookies（见 8.3）</li></ul><h3 id=ffmpeg-不存在>ffmpeg 不存在<a hidden class=anchor aria-hidden=true href=#ffmpeg-不存在>#</a></h3><ul><li>启用 universe 并安装（见第 6 节）</li></ul><h3 id=torch-import-报-ijit_notifyevent>torch import 报 iJIT_NotifyEvent<a hidden class=anchor aria-hidden=true href=#torch-import-报-ijit_notifyevent>#</a></h3><ul><li>降级 MKL/Intel OpenMP（见第 4 节）</li></ul><h3 id=nvidia-smi-正常但-torchcuda-false>nvidia-smi 正常但 torch.cuda False<a hidden class=anchor aria-hidden=true href=#nvidia-smi-正常但-torchcuda-false>#</a></h3><ul><li>添加 <code>/usr/lib/wsl/lib</code> 到 ldconfig（见第 5 节）</li><li>排查 <code>LD_LIBRARY_PATH</code> 劫持（见第 5.4 节）</li></ul><hr><h2 id=参考链接>参考链接<a hidden class=anchor aria-hidden=true href=#参考链接>#</a></h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-text-size-adjust:none><code class=language-text data-lang=text><span style=display:flex><span>https://github.com/yt-dlp/yt-dlp
</span></span><span style=display:flex><span>https://github.com/openai/whisper
</span></span><span style=display:flex><span>https://pytorch.org/get-started/locally/
</span></span><span style=display:flex><span>https://ffmpeg.org/
</span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://analyst-huang.github.io/>Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>