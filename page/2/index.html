<!doctype html><html lang=en dir=auto data-theme=auto><head><meta name=generator content="Hugo 0.154.5"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blog</title><meta name=description content><meta name=author content><link rel=canonical href=https://analyst-huang.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.343cc480b9ffc8f04ccbe5e968ad674880cab773ec19905e93033065c1e7a804.css integrity="sha256-NDzEgLn/yPBMy+XpaK1nSIDKt3PsGZBekwMwZcHnqAQ=" rel="preload stylesheet" as=style><link rel=icon href=https://analyst-huang.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://analyst-huang.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://analyst-huang.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://analyst-huang.github.io/apple-touch-icon.png><link rel=mask-icon href=https://analyst-huang.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://analyst-huang.github.io/index.xml title=rss><link rel=alternate type=application/json href=https://analyst-huang.github.io/index.json title=json><link rel=alternate hreflang=en href=https://analyst-huang.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51);color-scheme:dark}.list{background:var(--theme)}.toc{background:var(--entry)}}@media(prefers-color-scheme:light){.list::-webkit-scrollbar-thumb{border-color:var(--code-bg)}}</style></noscript><script>localStorage.getItem("pref-theme")==="dark"?document.querySelector("html").dataset.theme="dark":localStorage.getItem("pref-theme")==="light"?document.querySelector("html").dataset.theme="light":window.matchMedia("(prefers-color-scheme: dark)").matches?document.querySelector("html").dataset.theme="dark":document.querySelector("html").dataset.theme="light"</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\\\(",right:"\\\\)",display:!1},{left:"\\\\[",right:"\\\\]",display:!0}]})})</script><meta property="og:url" content="https://analyst-huang.github.io/"><meta property="og:site_name" content="Blog"><meta property="og:title" content="Blog"><meta property="og:locale" content="zh-cn"><meta property="og:type" content="website"><meta name=twitter:card content="summary"><meta name=twitter:title content="Blog"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Blog","url":"https://analyst-huang.github.io/","description":"","logo":"https://analyst-huang.github.io/favicon.ico","sameAs":[]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://analyst-huang.github.io/ accesskey=h title="Blog (Alt + H)">Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://analyst-huang.github.io/posts/ title=文章><span>文章</span></a></li><li><a href=https://analyst-huang.github.io/about/ title=关于><span>关于</span></a></li><li><a href=https://analyst-huang.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Diffusion</h2></header><div class=entry-content><p>t步加噪可以写成如下形式：
$x_t = \sqrt{\bar{\alpha}_t}\, x_0 + \sqrt{1 - \bar{\alpha}_t}\, \varepsilon,\quad \varepsilon \sim \mathcal{N}(0, I)$ 其中：
$\alpha_t = 1 - \beta_t,\quad \bar{\alpha}_t = \prod_{s=1}^{t} \alpha_s, \alpha_t \in [0,1] $ 二、严格推导：用贝叶斯公式（forward 后验） 1) 概率图结构与贝叶斯展开 从概率图（forward 链）： $ x_0 \rightarrow x_{t-1} \rightarrow x_t $ 由贝叶斯公式： $ q(x_{t-1}\mid x_t, x_0) = \frac{q(x_t\mid x_{t-1}, x_0)\,q(x_{t-1}\mid x_0)}{q(x_t\mid x_0)}. $ 由于 forward 过程的马尔可夫性： $ q(x_t\mid x_{t-1}, x_0)=q(x_t\mid x_{t-1}), $ 因此： $ q(x_{t-1}\mid x_t, x_0) = \frac{q(x_t\mid x_{t-1})\,q(x_{t-1}\mid x_0)}{q(x_t\mid x_0)}. $ ...</p></div><footer class=entry-footer><span title='2026-01-08 00:00:00 +0000 UTC'>January 8, 2026</span>&nbsp;·&nbsp;<span>4 min</span></footer><a class=entry-link aria-label="post link to Diffusion" href=https://analyst-huang.github.io/posts/ai/diffusion/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>uv</h2></header><div class=entry-content><p>最近又在配一个环境，所以想到了之前被同事推荐过的uv。因为发现在conda环境中也可以用，而且比pip快很多，所以记录一下uv的用法。
看了一下，发现和科研需求并没有那么重合，记录一下和GPT的几个问题：
Conda vs uv：科研工作流下依赖管理的真实差异（Q&amp;A） 面向读者：长期使用 conda + pip 的科研/工程混合用户（如深度学习、机器人、CUDA 相关项目），在接触 uv / poetry 等“项目化依赖管理工具”时感到困惑的人。
Q1：我一直用 conda 建环境 + pip / conda install 装包，这样有什么问题吗？ A：没有问题，而且这是科研圈的主流做法。
你的典型流程是：
conda create -n xxx python=3.10 conda activate xxx pip install ... 或 conda install ... 稳定后：conda env export > env.yaml 这个流程的特点是：
环境层面高度可控 CUDA / PyTorch / 编译依赖更容易处理 适合频繁试错和快速实验 在深度学习与机器人领域，这种方式依然是现实最优解之一。
Q2：那 uv 到底在解决什么问题？为什么工程界很推它？ A：uv 的核心目标不是“更好地装包”，而是“让项目自带可复现环境定义”。
uv 想解决的是这些问题：
clone 一个 repo 后，一条命令就能得到一致环境 CI / 多人协作环境一致 依赖升级过程可审计、可回滚 因此它强调：
...</p></div><footer class=entry-footer><span title='2026-01-08 00:00:00 +0000 UTC'>January 8, 2026</span>&nbsp;·&nbsp;<span>2 min</span></footer><a class=entry-link aria-label="post link to uv" href=https://analyst-huang.github.io/posts/%E5%A6%99%E5%A6%99%E5%B7%A5%E5%85%B7/uv/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Codex</h2></header><div class=entry-content><p>由于最近发现Codex非常好用，并且众多业界大牛一起指出Vibe Coding是未来的趋势，所以系统学习一下Codex。或许人类真的已经来到了理解复杂系统的时候了。
感觉总体来说使用方法是相当自然的，唯一需要注意的是最近新增加的skill功能。原来是anthropic提出的标准，现在被大量采纳，估计会是一个会持续很多年的标准，值得学习。
Agent Skills 基本格式 官网与完整规范：https://agentskills.io/
1) 目录结构 一个 Skill 就是一个文件夹，至少包含一个 SKILL.md：
skill-name/ └── SKILL.md 可选：
scripts/：可执行脚本 references/：参考文档 assets/：模板或资源 2) SKILL.md 格式 SKILL.md 分为两部分：
(A) YAML Frontmatter（必需） --- name: skill-name description: 该技能做什么，以及在什么情况下使用 --- 约束：
name 必须与文件夹名一致 仅允许小写字母、数字、连字符 - 1–64 字符，不能以 - 开头或结尾，不能有连续 -- description 为 1–1024 字符 (B) Markdown 正文（指令内容） Frontmatter 之后是普通 Markdown，用来写操作步骤、示例、注意事项等，结构不强制。
3) 最小示例 --- name: pdf-processing description: 提取 PDF 文本与表格，用于后续分析或填表。 --- # PDF Processing ## When to use 当用户需要处理 PDF 文件时。 ## Procedure 1. 读取 PDF 2. 提取文本与表格 3. 输出结构化结果 这就是 Agent Skill 的基本格式。更多细节见官网：https://agentskills.io/
...</p></div><footer class=entry-footer><span title='2026-01-07 00:00:00 +0000 UTC'>January 7, 2026</span>&nbsp;·&nbsp;<span>3 min</span></footer><a class=entry-link aria-label="post link to Codex" href=https://analyst-huang.github.io/posts/%E5%A6%99%E5%A6%99%E5%B7%A5%E5%85%B7/codex/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>PPO调参手册</h2></header><div class=entry-content><p>网络的大小对训练和收敛的速度有极大的影响 很多时候[256, 256]就已经足够</p></div><footer class=entry-footer><span title='2026-01-03 00:00:00 +0000 UTC'>January 3, 2026</span>&nbsp;·&nbsp;<span>1 min</span></footer><a class=entry-link aria-label="post link to PPO调参手册" href=https://analyst-huang.github.io/posts/ai/ppo%E8%B0%83%E5%8F%82%E6%89%8B%E5%86%8C/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>ELBO：证据、隐变量与变分下界的统一视角</h2></header><div class=entry-content><p>ELBO：证据、隐变量与变分下界的统一视角 本文给出一个可重复推导、可迁移到多种 AI 场景（VAE、世界模型、序列潜变量模型、变分推断等）的 ELBO（Evidence Lower Bound）理解框架。核心主线是：
训练目标始终是最大化 证据（边缘似然）。 隐变量不是深度学习才有的“工程拆解”，而是统计建模与推断的长期核心工具；ELBO 则是经典“下界化 + 可优化”范式的现代实现。 ELBO 中显式出现的先验 KL 与“逼近真实后验”的 KL 并不矛盾：前者是目标函数的结构项，后者是 ELBO 与证据之间的缺口（gap）。 1. “证据”到底是什么 给定观测数据 $x$ 与生成模型参数 $\theta$，所谓 **证据（evidence）**是数据在模型下出现的概率： $p_\theta(x)$
它也常被称为 边缘似然（marginal likelihood）、模型证据（model evidence）。当模型含潜变量 $z$ 时，证据是对潜变量积分（或求和）后的量：
$p_\theta(x)=\int p_\theta(x,z)\,dz$ 如果进一步将联合分布写成“先验 + 条件似然”的形式：
$p_\theta(x,z)=p_\theta(x\mid z)\,p(z)$ 则证据变为：
$p_\theta(x)=\int p_\theta(x\mid z)\,p(z)\,dz$ 这句话的统计含义非常直接：模型整体（在不知道真实潜变量的情况下）生成 $x$ 的能力。在贝叶斯公式中，它是后验归一化因子：
$p_\theta(z\mid x)=\frac{p_\theta(x\mid z)p(z)}{p_\theta(x)}$ 因此，“证据”并不是某个特定解释 $z^*$ 的质量，而是所有可能解释对 $x$ 的总体支持度。
2. 隐变量在统计中的地位：不是工程权宜，而是核心范式 隐变量（latent variables）在统计中长期处于中心位置，原因主要有两类：
...</p></div><footer class=entry-footer><span title='2026-01-02 00:00:00 +0000 UTC'>January 2, 2026</span>&nbsp;·&nbsp;<span>2 min</span></footer><a class=entry-link aria-label="post link to ELBO：证据、隐变量与变分下界的统一视角" href=https://analyst-huang.github.io/posts/ai/elbo/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>PPO：策略梯度、重要性采样与 Clip</h2></header><div class=entry-content><p>PPO 中的策略梯度、重要性采样与概率密度比 从策略梯度定理出发，经由重要性采样与“对梯度的不定积分”，理解 PPO 的 surrogate objective 与 Clip 机制。
1. 策略梯度定理：起点而不是终点 策略梯度定理给出的是梯度形式，而不是一个可直接优化的损失函数：
$$ \nabla_\theta J(\theta) = \mathbb E_{\pi_\theta} \big[ \nabla_\theta \log \pi_\theta(a_t\mid s_t), A^\pi(s_t,a_t) \big]. $$ 这一定理说明了：
梯度方向由 $ \nabla_\theta \log \pi $决定； 学习信号由优势函数 $A$ 提供； 它本质上是 on-policy 的结论。 但工程上我们并不是直接“写梯度”，而是希望：
构造一个目标函数 $L(\theta)$，使其梯度自动给出合理的策略更新。
这正是 PPO / TRPO 所做的事情。
2. 从 on-policy 到 off-policy：重要性采样的引入 在实践中：
rollout 使用的是旧策略 $ \pi_{\text{old}} $； 更新时参数已经变为 $ \pi_\theta $。 于是需要通过重要性采样来修正期望的测度：
$$ \mathbb E_{\pi_\theta}[f(s,a)] = \mathbb E_{\pi_{\text{old}}} \left[ \frac{\pi_\theta(a\mid s)}{\pi_{\text{old}}(a\mid s)} f(s,a) \right]. $$ 定义重要性采样率（概率比 / 密度比）：
...</p></div><footer class=entry-footer><span title='2025-12-31 00:00:00 +0000 UTC'>December 31, 2025</span>&nbsp;·&nbsp;<span>2 min</span></footer><a class=entry-link aria-label="post link to PPO：策略梯度、重要性采样与 Clip" href=https://analyst-huang.github.io/posts/ai/ppo/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>分析哲学与小说结构</h2></header><div class=entry-content><p>最近复习完分析哲学的期末考试，虽然从结构主义视角下看这些理论都有些意识形态偏见和过分的与现实脱节，但是在言语层面的复杂结构正好可以用来作为叙事的骨架，甚至是肌肉。一个理论，在其失败之处，或是在其成功之处，如果不是因为其符号系统内部矛盾而发生的解离，那么一定是因为实在界的入侵而解离了。实在界的入侵，正是人物的、剧情的矛盾所在。我们都是在大他者所规定的世界里活着，时有运行不畅之处，那正是小说发生的地方。而尝试将大他者说清楚到底是什么，问题在哪里，这是分析哲学可以提供的东西。分析哲学基于资本主义伦理观/后科学时代自然观，尝试分析出话语的边界，虽然说它不可能触及被蓄意遮蔽的东西，但是能触及的那些概念，像自由意志、心灵等等，已经可以构成小说的一部分结构了。我们接下来对关于“自由意志”的法兰克福案例进行分析。
Harry Frankfurt 案例的叙事核心 在小说/叙事层面，法兰克福案例的真正贡献不是：否认自由意志，证明决定论，玩反事实逻辑游戏，而是这一点：即使主体在行动中具有自由意志，自由意志也不再是伦理与世界反应的决定性变量。这是对法兰克福案例的一个倒置，因为其原来用于说明自由意志的要求没有那么高，即不要求本可以不这么做。我们必须将其倒置，因为小说的关键成分就在于一个被认为有自由意志的主体，否则角色的挣扎、关系的变换都将失去张力。换句话说：自由意志仍然存在（主体内部），但它失去了“让世界必须回应它”的权力，这是一个典型的悲剧内核。
小说母题 我们最终沉淀出的母题可以表述为：
主体在真实地行动、判断、付出努力， 并不断制造“我影响了世界”的因果幻象； 但世界运行在另一套评价与决策维度中， 自由意志与努力既不被否定，也不被采用。
一句更锋利的版本是：
自由意志存在，但与世界毫无关系。
不是被压制、被否认、被证明为假， 而是被正确理解、却被绕开。
更多的分析哲学理论的叙事化改造 模态实在论：可能世界的模态实在论观点作为科幻小说的底层架构支持上层叙事 盖梯尔案例：以JTB的形式作为主角的动机结构，但是后面会让这个“知道”变成不知道，达成叙事张力 …</p></div><footer class=entry-footer><span title='2025-12-30 00:00:00 +0000 UTC'>December 30, 2025</span>&nbsp;·&nbsp;<span>1 min</span></footer><a class=entry-link aria-label="post link to 分析哲学与小说结构" href=https://analyst-huang.github.io/posts/%E6%9D%82%E8%B0%88/%E5%88%86%E6%9E%90%E5%93%B2%E5%AD%A6-%E5%B0%8F%E8%AF%B4%E7%BB%93%E6%9E%84/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>策略梯度定理</h2></header><div class=entry-content><p>策略梯度：从 REINFORCE 到策略梯度定理（含详细证明） 本文目标：
用统一符号说明策略梯度家族的“同一梯度、两种坐标系”本质； 给出 REINFORCE（Williams, 1992）的 score-function / likelihood-ratio 推导； 给出 Sutton et al.（1999）式 策略梯度定理（Policy Gradient Theorem） 的 Bellman/占用测度推导； 0. 记号与设定 我们考虑离散时间、可数（或有限）状态动作的折扣 MDP：
状态：$s\in\mathcal S$ 动作：$a\in\mathcal A$ 转移：$P(s’\mid s,a)$ 即时奖励：$r(s,a)$（或 $r_t$） 折扣：$\gamma\in(0,1)$ 初始状态分布：$\mu(s)=\Pr(s_0=s)$ 随机策略以参数 $\theta$ 参数化：$\pi_\theta(a\mid s)$。
定义折扣回报（episode 有限长度 $T$ 或无穷长度均可；下文为便于书写采用有限 $T$，无穷时取极限）：
$$ R(\tau):=\sum_{t=0}^{T}\gamma^t r_{t+1}. $$
目标函数（期望折扣回报）：
$$ J(\theta)=\mathbb E_{\tau\sim p_\theta}[R(\tau)]. $$
其中轨迹 $\tau$ 表示 $ \tau=(s_0,a_0,r_1,s_1,a_1,r_2,\ldots,s_T,a_T,r_{T+1}) $ ，轨迹分布为
$$ p_\theta(\tau)=\mu(s_0)\prod_{t=0}^{T}\pi_\theta(a_t\mid s_t),P(s_{t+1}\mid s_t,a_t). $$
关键点：环境动力学 $P$ 与初始分布 $\mu$ 不依赖 $\theta$。$\theta$ 只通过策略 $\pi_\theta$ 进入。
...</p></div><footer class=entry-footer><span title='2025-12-30 00:00:00 +0000 UTC'>December 30, 2025</span>&nbsp;·&nbsp;<span>3 min</span></footer><a class=entry-link aria-label="post link to 策略梯度定理" href=https://analyst-huang.github.io/posts/ai/%E7%AD%96%E7%95%A5%E6%A2%AF%E5%BA%A6%E5%AE%9A%E7%90%86/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>认识论（怀疑论）</h2></header><div class=entry-content><p>认识论 · 怀疑论（Epistemology: Skepticism） 课程：Introduction to Philosophy
主题：Epistemology – Skepticism
讲义来源：北大 Bin Zhao 教授课程讲义 :contentReference[oaicite:0]{index=0}
一、什么是怀疑论（Skepticism） 基本主张
怀疑论者主张： 我们并不知道（或没有正当理由相信）许多我们平常以为自己知道的事情。
1. 怀疑论主张的两个维度 力度（Force）
否认的认识地位类型： 知识（knowledge） 正当信念（justified belief） 证据（evidence） 范围（Scope）
被怀疑的信念类型： 外部世界信念 关于未来的信念 关于未观察事物的信念 ⚠️ 重要澄清
怀疑论者并不声称这些信念是假的 只是否认：我们“知道”它们 例如：无神论者并不是（相关意义上的）怀疑论者 二、三种经典怀疑论论证 （一）错误可能性论证 The Possibility of Error Argument
几乎所有关于外部世界的信念，都可能是错误的 如果你对 p 的信念可能是错误的，那么你就不知道 p 所以：你几乎不知道任何关于外部世界的事情 （二）确定性论证 The Certainty Argument
如果你知道 p，那么你必须对 p 绝对确定 你对任何外部世界命题都不是绝对确定的 所以：你不知道任何关于外部世界的事情 区分
心理确定性（psychological certainty） 认识论确定性（epistemic certainty）：拥有最强理由 （三）传递性论证 The Transmissibility Argument
设定：
...</p></div><footer class=entry-footer><span title='2025-12-26 00:00:00 +0000 UTC'>December 26, 2025</span>&nbsp;·&nbsp;<span>2 min</span></footer><a class=entry-link aria-label="post link to 认识论（怀疑论）" href=https://analyst-huang.github.io/posts/2025%E7%A7%8B%E5%A4%96%E5%93%B2%E6%89%80%E5%93%B2%E5%AD%A6%E5%AF%BC%E8%AE%BA%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A4%E8%AF%86%E8%AE%BA3/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>认识论（知识分析）</h2></header><div class=entry-content><p>Epistemology：The Analysis of Knowledge （知识论：知识的分析）复习笔记
一、什么是知识论（Epistemology） 知识论研究以下问题：
什么是知识（knowledge） 什么是辩护/证成（justification） 什么是证据（evidence） 我们何时有理由相信某事 命题知识（Propositional Knowledge） 表达形式：S knows that p p 是命题（proposition） 命题可真可假 为真的命题对应事实（facts） 二、分析（Analysis）与反例（Counterexample） 分析 X：试图给出 X 的精确定义
例：
Mother = a woman who has given birth
反例：
有 X 但不满足定义 或满足定义但不是 X 三种回应策略：
修改被分析项（X） 修改分析条件 否认反例直觉 三、JTB 分析（Justified True Belief） JTB：
S 知道 p
iff
(1) p 为真
(2) S 相信 p
(3) S 对 p 的信念是有辩护的
支持理由 不可能“知道假命题” 不可能“知道却不相信” 猜对 ≠ 知识 四、Gettier 案例（对 JTB 的反例） Gettier 的基本结构 主体有一个通常会导致假信念的证成 该信念由于无关的巧合而为真 经典案例 十枚硬币案例 Ford / Barcelona 案例 田野里的羊 结论：
...</p></div><footer class=entry-footer><span title='2025-12-26 00:00:00 +0000 UTC'>December 26, 2025</span>&nbsp;·&nbsp;<span>2 min</span></footer><a class=entry-link aria-label="post link to 认识论（知识分析）" href=https://analyst-huang.github.io/posts/2025%E7%A7%8B%E5%A4%96%E5%93%B2%E6%89%80%E5%93%B2%E5%AD%A6%E5%AF%BC%E8%AE%BA%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A4%E8%AF%86%E8%AE%BA1/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://analyst-huang.github.io/>«&nbsp;Prev&nbsp;
</a><a class=next href=https://analyst-huang.github.io/page/3/>Next&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2026 <a href=https://analyst-huang.github.io/>Blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script></body></html>