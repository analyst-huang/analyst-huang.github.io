---
title: "uv"
date: 2026-01-08
draft: False 
---
最近又在配一个环境，所以想到了之前被同事推荐过的*uv*。因为发现在conda环境中也可以用，而且比pip快很多，所以记录一下*uv*的用法。

看了一下，发现和科研需求并没有那么重合，记录一下和GPT的几个问题：

# Conda vs uv：科研工作流下依赖管理的真实差异（Q&A）

> 面向读者：长期使用 conda + pip 的科研/工程混合用户（如深度学习、机器人、CUDA 相关项目），在接触 uv / poetry 等“项目化依赖管理工具”时感到困惑的人。

---

## Q1：我一直用 conda 建环境 + pip / conda install 装包，这样有什么问题吗？

**A：没有问题，而且这是科研圈的主流做法。**

你的典型流程是：

1. `conda create -n xxx python=3.10`
2. `conda activate xxx`
3. `pip install ...` 或 `conda install ...`
4. 稳定后：`conda env export > env.yaml`

这个流程的特点是：

* 环境层面高度可控
* CUDA / PyTorch / 编译依赖更容易处理
* 适合频繁试错和快速实验

在深度学习与机器人领域，这种方式依然是现实最优解之一。

---

## Q2：那 uv 到底在解决什么问题？为什么工程界很推它？

**A：uv 的核心目标不是“更好地装包”，而是“让项目自带可复现环境定义”。**

uv 想解决的是这些问题：

* clone 一个 repo 后，一条命令就能得到一致环境
* CI / 多人协作环境一致
* 依赖升级过程可审计、可回滚

因此它强调：

> 项目应当携带自己的依赖声明，而不是依赖某个外部环境。

这在库开发、产品工程中非常重要，但在科研探索阶段并非刚需。

---

## Q3：uv 里的 pyproject.toml 和 uv.lock 是干嘛的？为什么要两个文件？

**A：它们分别记录“依赖意图”和“依赖结果”。**

### pyproject.toml：依赖意图层（人维护）

表示：

> 我的项目逻辑上需要哪些库，大概什么版本范围。

示例：

```toml
[project]
dependencies = [
  "torch>=2.1",
  "numpy",
  "timm",
]
```

类似于增强版的 `requirements.txt`。

---

### uv.lock：依赖结果层（机器维护）

表示：

> 在当前平台上，这次解析出来的一整套精确依赖版本组合。

包含所有直接与间接依赖：

* torch 的具体 patch 版本
* triton / nvidia 库
* numpy 精确版本

类似于自动维护的 `pip freeze`。

---

### 为什么要分开？

因为工程上需要同时满足：

* 人只关心“我需要什么功能库”
* 机器负责“选出一组兼容的具体版本”

如果只用一个锁死的环境文件：

* 升级一个包会变得非常痛苦
* 无法区分哪些依赖是主动选择，哪些是被动引入

---

## Q4：我用 conda 升级一个包，其他依赖也会自动调整，最后导出 env.yaml，不是一样可复现吗？

**A：在“能否复现”层面是一样的，在“工程可维护性”层面差异很大。**

conda env.yaml 记录的是：

> 当前整个环境的最终状态快照。

但它无法表达：

* 哪些包是你主动升级的
* 哪些是 solver 为满足约束被迫调整的

结果是：

* 升级后性能或结果变化
* 很难定位是哪组依赖变化导致

---

在 lockfile 工作流中：

```bash
git diff uv.lock
```

可以直接看到：

* torch: 2.1.1 → 2.1.2
* triton: 2.0 → 2.1
* numpy: 1.26.2 → 1.26.4

这是**可审计的依赖变更历史**，对多人协作和长期维护非常关键。

---

## Q5：为什么工程界不用 conda env.yaml 做项目依赖管理？

**A：因为 env.yaml 是“环境快照”，不是“项目依赖规范”。**

主要问题包括：

* 平台强绑定（Linux / Windows / CUDA 版本差异）
* 底层库噪声极多（glibc、libgcc 等）
* 合并依赖极其困难
* 无法表达依赖升级策略

工程界更关心的是：

> 项目需要哪些 Python 依赖，而不是某台机器当前装了什么。

这就是 pyproject + lockfile 范式存在的原因。

---

## Q6：那在 CUDA / 深度学习场景下，uv 真的能完全替代 conda 吗？

**A：基本不能，至少目前不现实。**

因为：

* CUDA / cuDNN / NCCL 等仍高度依赖系统库
* PyTorch 官方仍优先支持 conda 发行渠道
* 编译型包（flash-attn, xformers）仍强依赖本地 toolchain

因此在现实科研环境中，更常见的是：

> conda 管系统级与 CUDA 相关依赖
> pip / uv 管 Python 级依赖

而不是完全用 uv 接管一切。

---

## Q7：那对科研用户来说，uv 有没有实际价值？

**A：有，但主要体现在“pip 加速器 + 更稳定 resolver”这一层。**

推荐的低成本用法是：

```bash
conda activate myenv
uv pip install flash-attn xformers timm
```

优点：

* 明显比 pip 快
* 更好的依赖解析
* 不改变你原有 conda 工作流

不需要：

* pyproject.toml
* uv.lock
* uv venv

只把 uv 当成 pip 的替代即可。

---

## Q8：总结一下，conda 流与 uv 流本质区别是什么？

可以理解为两种完全不同的范式：

| 维度   | conda 工作流      | uv / poetry 工作流 |
| ---- | -------------- | --------------- |
| 核心对象 | 环境             | 项目              |
| 依赖记录 | 环境快照           | 项目依赖 + 锁文件      |
| 升级粒度 | 整体环境           | 单个依赖意图          |
| 适合场景 | 科研实验 / CUDA 密集 | 工程协作 / CI       |
| 灵活性  | 高              | 中               |
| 可审计性 | 低              | 高               |

两者并非替代关系，而是针对不同问题设计。

---

## 一句话版结论

* conda env.yaml = 环境状态快照
* pyproject.toml = 项目依赖意图
* uv.lock = 精确依赖结果锁定

科研场景关注“环境能跑”，工程场景关注“项目可复现”，
两套工具各自服务于不同优先级。
